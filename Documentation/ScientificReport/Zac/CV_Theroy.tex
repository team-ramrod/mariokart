\section{Computer Vision Theory and Background}

A large number of algorithms exist for locating a marker in a video feed, however to be appropriate for the task at hand the algorithms had to have several key features besides simply finding the marker. 

\begin{itemize}
\item The algorithm had to be able to reliably give the position of the marker relative to the kart including an accurate estimate of the distance from the kart
\item It had to work even when the marker was moving quickly across the camera and at a large distance from the camera. 
\item It had to be robust to the large variations in lighting conditions and backgrounds that it would experience when mounted to the kart. 
\item Finally it had to be able to be performed in real time giving out information on the position of the objects location with little lag and at a high refresh rate. 
\end{itemize}
Based on these criteria three methods were found that showed promise at being able to meet these requirements.

Colour detection was the first process looked at. This approach takes the cameras image and converts it to HSV (hue, saturation and value) space \cite{hsv}. In this space each pixel is classified by its hue or colour, its saturation which is the intensity of the colour and its value which represents how light or dark the colour is. This hue is assumed to vary very little for the marker. For the most simple form of colour tracking the image is tresholded for a range around the colour of the marker being tracked. This process leaves only the desired colour present in the resulting image. The x and y positions are found by finding the location of the centre of the resulting blob in the thresholded image. The distance of the marker is taken to be proportional to the inverse of the square root of the markers size in pixels.

Chessboard detection is often used in augmented reality applications to get the position of a marker relative to a camera.  It is used so that a 3d model can be displayed with the correct size and orientation as if it was actually present in the scene \cite{augmented}. This algorithm uses a chessboard of known size as its marker. It thresholds the image and applies a Harris corner detector to find the corners in the image. This information is combined with a Hough transform to find the lines on the chessboard and once all the corners and lines have been found the image is searched for a pattern of them that would match the chessboards geometry \cite{chessboard}. This method considers all of the intrinsic parameters of the camera as well as the extrinsic transformation for the chessboards location in the scene. This means that the position of the chessboard marker can be accurately computed even taking into  account the curving effect of the cameras lens at the corners allowing for more accurate marker location. 

The third method examined for detecting a marker in a scene was the SURF (speeded up robust features) algorithm. This algorithm operates along very similar lines to the SIFT (scale invariant features transformation) algorithm except operating at a greater rate, hence the reason for the "speeded up" in its name. The SURF algorithm matches points that are common to two separate images. In this case the images are a unique marker and an image of a scene in which the marker is located. The algorithm operates by first selecting a large number of unique points in the first image. Finding these points involves finding areas of the image that are unique in their surroundings and that can be easily identified regardless of changes to the viewpoint \cite{surf}. By themselves these points could not be located in a new image as a one dimensional point cannot be identified as different from any other point and so a small window surrounding each point is also saved. Each new frame of the scene is then scanned for areas that match these windows using Harr like features to make this match \cite{haar_like}.

Once the points are matched another algorithm RANSAC (RANdom SAmple Consensus) was used to extract the size and orientation of the marker from the scene. RANSAC itself is not a computer vision algorithm but an iterative method to find parameters of a mathematical model within noisy data where redundancy in the number of points exists \cite{cosc428}. RANSAC works by randomly selecting four points in the image and from this working out the transformations the picture has undergone to fit these four points in the scene. Using this transformation a calculated location is found for all the other points. The distance between where a point is calculated to have been and where it actually lies in the image is found. This gives an estimation of the error in the transformations that the picture has undergone. If this error is small the transformation is kept and taken as correct, if it is large the process is repeated with four new points \cite{ransac}.