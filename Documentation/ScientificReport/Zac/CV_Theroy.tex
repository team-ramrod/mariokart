\section{Computer Vision Solutions Theroy}

A large number of algorithms exist for tracking an object in a video feed. Some of the more common were examined to determine how appropriate they would be for performing the task of tracking an object which the go-kart could follow. To perform this task the algorithm had to be able to reliably give the position of the object relative to the kart including an accurate estimate as to the distance from the kart. It also had to work even when the object was moving quickly across the camera and at a large distance from the camera. It had to be robust to the large variations in lighting conditions and backgrounds that it would experience when mounted to the kart. It had to be able to be performed in real time giving out information on the position of the objects location with little lag and at a high refresh rate

Color detection was the first process looked at. This approach took the cameras image and converted it to HSV (hue, saturation and value) space [1]. In this space each pixel was classified by its hue or color, its saturation which is the intensity of the color and its value which represents how light or dark the color is. This hue was then taken to vary by very small amounts  for the object during the tracking. For the most simple form of color tracking the image was then tresholded by a color in the range of the object being tracked. This would leave only the desired color present on the screen. A more robust form of color detection is the camshaft algorithm. This algorithm takes in a region around the object to track and creates a histogram of the hues present. It then scans successive frames for regions whose color distributions closely match the histogram.  

Chessboard detection is often used in augmented reality applications to get the position of a marker relative to a camera so that a 3d model can be displayed with the correct size and orientation [4]. This algorithm uses a chessboard of known size as its marker. It thresholds the image, applies a Harris corner detection to find the corners in the image this is combined with a Hough transform to find the lines on the chessboard. Once all the corners and lines have been found the image is searched for a pattern of them that would give the chessboard [3]. This method considers all of the intrinsic parameters of the camera as well as the extrinsic transformation for the chessboards location in the scene. This means that the position of the chessboard marker can be accurately computed even taking into  account the curving effect of the cameras lens at the corners. 

A second method for detecting a marker in a scene is the SURF (speeded up robust features) algorithm. This algorithm operates along very similar lines to the SIFT (scale invariant features transformation) algorithm except operating at a greater rate, hence the reason for the "speeded up" in its name. The surf algorithm matches points that are common to two separate images. In this case the images are a unique marker and an image of a scene in which the marker is located. The algorithm operates by selecting a large number of unique points. Finding these points involves finding areas of an image that are unique in there surroundings and that can be easily identified regardless of changes to the viewpoint [5]. By themselves these points could not be located in a new image so instead a small window surrounding each point is also saved. Each new frame of the scene is then scanned for areas that match these points. SURF uses Harr like features to make this match.

Once the points are matched a second algorithm RANSAC (RANdom SAmple Consensus) can be used to extract the size and orientation of the object from the scene. RANSAC itself is not a computer vision algorithm but an iterative method to find parameters of a mathematical model within noisy data where redundancy in the number of points exists [7]. RANSAC works by randomly selecting four points in the image and from this working out the transformations the picture has undergone to fit these four points in the scene. Using this transformation a calculated location is found for all the other points. The distance between where a point is calculated to have been and where it actually lies in the image is found. This gives an estimation of the error in the transformations that the picture has undergone. If this error is small the transformation is kept and taken as correct, if it is large the process is repeated with four new points.